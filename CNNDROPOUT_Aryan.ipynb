{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6c3e8cc",
   "metadata": {},
   "source": [
    "# Deep Learning Lab: CNN with Data Augmentation and Dropout (MNIST)\n",
    "\n",
    "**Target audience:** 2nd Year B.Tech  \n",
    "**Goal:** Train a CNN on MNIST and understand:\n",
    "- Why CNNs are better than MLPs for images\n",
    "- Data Augmentation (to reduce overfitting)\n",
    "- Dropout (regularization)\n",
    "- Train vs Validation curves (overfitting detection)\n",
    "\n",
    "> Run cells **top to bottom**. This notebook trains **two models**:\n",
    "1. CNN **without** Dropout (baseline)\n",
    "2. CNN **with** Dropout (regularized)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7151073",
   "metadata": {},
   "source": [
    "## 1) Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08692c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff236af1",
   "metadata": {},
   "source": [
    "## 2) Load MNIST Dataset\n",
    "\n",
    "MNIST contains 28×28 grayscale images of handwritten digits (0–9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd2215",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"Train:\", x_train.shape, y_train.shape)\n",
    "print(\"Test :\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89e9cf",
   "metadata": {},
   "source": [
    "### Normalize + Add Channel Dimension\n",
    "\n",
    "CNN expects input shape: **(height, width, channels)**.\n",
    "MNIST is grayscale → channels = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d30e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test  = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Add channel dimension: (N, 28, 28) -> (N, 28, 28, 1)\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test  = x_test[..., tf.newaxis]\n",
    "\n",
    "print(\"After preprocessing:\")\n",
    "print(\"Train:\", x_train.shape)\n",
    "print(\"Test :\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc35a3",
   "metadata": {},
   "source": [
    "### Visualize a Few Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(x_train[i].squeeze(), cmap=\"gray\")\n",
    "    plt.title(int(y_train[i]))\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ffe3a5",
   "metadata": {},
   "source": [
    "## 3) Data Augmentation\n",
    "\n",
    "**Why?** It increases the diversity of training images by applying random transformations.\n",
    "This helps the model generalize better and reduces overfitting.\n",
    "\n",
    "We will use:\n",
    "- RandomRotation\n",
    "- RandomZoom\n",
    "- RandomTranslation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc5c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomRotation(0.08),\n",
    "    layers.RandomZoom(0.10),\n",
    "    layers.RandomTranslation(0.08, 0.08),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "data_augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909a375",
   "metadata": {},
   "source": [
    "### Preview Augmented Images (same image, different versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = x_train[0:1]  # one image\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "for i in range(10):\n",
    "    augmented = data_augmentation(sample, training=True)\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(augmented[0].numpy().squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Augmented versions of the same image\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f333dee",
   "metadata": {},
   "source": [
    "## 4) Model A: CNN (Baseline) — **No Dropout**\n",
    "\n",
    "Architecture:\n",
    "- Data Augmentation\n",
    "- Conv(32) + MaxPool\n",
    "- Conv(64) + MaxPool\n",
    "- Flatten\n",
    "- Dense(128)\n",
    "- Dense(10, softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd257f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_baseline():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(28,28,1)),\n",
    "        data_augmentation,\n",
    "        layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ], name=\"CNN_Baseline_NoDropout\")\n",
    "    return model\n",
    "\n",
    "model_a = build_cnn_baseline()\n",
    "model_a.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ae18b",
   "metadata": {},
   "source": [
    "### Compile & Train Model A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_a = model_a.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f130353",
   "metadata": {},
   "source": [
    "## 5) Plot Curves for Model A\n",
    "\n",
    "Look for overfitting signs:\n",
    "- Training accuracy keeps increasing\n",
    "- Validation accuracy stops improving / decreases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(title + \" (Loss)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history_a, \"Model A: CNN Baseline (No Dropout)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873e90ce",
   "metadata": {},
   "source": [
    "## 6) Model B: CNN with Dropout (Regularization)\n",
    "\n",
    "**Dropout** randomly turns off some neurons during training:\n",
    "- reduces memorization (overfitting)\n",
    "- improves generalization\n",
    "\n",
    "We add dropout:\n",
    "- after pooling layers (0.25)\n",
    "- before final classification (0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c469a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_with_dropout():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(28,28,1)),\n",
    "        data_augmentation,\n",
    "        layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(0.50),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ], name=\"CNN_WithDropout\")\n",
    "    return model\n",
    "\n",
    "model_b = build_cnn_with_dropout()\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45613bbe",
   "metadata": {},
   "source": [
    "### Compile & Train Model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d457f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_b = model_b.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334fb675",
   "metadata": {},
   "source": [
    "## 7) Plot Curves for Model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874fd34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_b, \"Model B: CNN + Dropout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a97bf8",
   "metadata": {},
   "source": [
    "## 8) Compare Final Test Accuracy\n",
    "\n",
    "We evaluate both models on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5342e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_a, test_acc_a = model_a.evaluate(x_test, y_test, verbose=0)\n",
    "test_loss_b, test_acc_b = model_b.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Model A (No Dropout)  - Test Accuracy:\", round(test_acc_a, 4), \" Test Loss:\", round(test_loss_a, 4))\n",
    "print(\"Model B (With Dropout) - Test Accuracy:\", round(test_acc_b, 4), \" Test Loss:\", round(test_loss_b, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0199658f",
   "metadata": {},
   "source": [
    "## 9) Predict on a Few Test Images\n",
    "\n",
    "We show predicted labels vs actual labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model, x, y, n=10):\n",
    "    preds = model.predict(x[:n], verbose=0)\n",
    "    pred_labels = np.argmax(preds, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(8,3))\n",
    "    for i in range(n):\n",
    "        plt.subplot(2,5,i+1)\n",
    "        plt.imshow(x[i].squeeze(), cmap=\"gray\")\n",
    "        plt.title(f\"P:{pred_labels[i]} / T:{y[i]}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Predictions using Model B (Dropout):\")\n",
    "show_predictions(model_b, x_test, y_test, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d50eb2",
   "metadata": {},
   "source": [
    "## 10) Student Exercises (Lab Tasks)\n",
    "\n",
    "1. Increase epochs to 10 and compare overfitting behavior.  \n",
    "2. Change dropout rates (0.1, 0.3, 0.7) and observe performance.  \n",
    "3. Remove data augmentation and check whether overfitting increases.  \n",
    "4. Try CIFAR-10 dataset (harder): `tf.keras.datasets.cifar10`.  \n",
    "5. Add Batch Normalization after convolution layers and compare.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedbb168",
   "metadata": {},
   "source": [
    "## 11) Quick Viva Questions\n",
    "\n",
    "- Why is CNN better than MLP for images?  \n",
    "- What does a convolution filter learn?  \n",
    "- Why do we use MaxPooling?  \n",
    "- What is overfitting? How do you detect it?  \n",
    "- How does Data Augmentation help?  \n",
    "- How does Dropout reduce overfitting?  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
